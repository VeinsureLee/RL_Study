from Return_Func import compute
import numpy as np
S = ["s1","s2","s3","s4","s5"] # 状态集合
A = ["保持 s1","前往 s1","前往 s2","前往 s3","前往 s4","前往 s5","概率前往"] # 动作集合
# 状态转移函数
P = {
    "s1-保持 s1-s1":1.0, "s1-前往 s2-s2":1.0,
    "s2-前往 s1-s1":1.0, "s2-前往 s3-s3":1.0,
    "s3-前往 s4-s4":1.0, "s3-前往 s5-s5":1.0,
    "s4-前往 s5-s5":1.0, "s4-概率前往-s2":0.2,
    "s4-概率前往-s3":0.4, "s4-概率前往-s4":0.4,
}

# 奖励函数
R = {
    "s1-保持 s1":-1, "s1-前往 s2":0,
    "s2-前往 s1":-1, "s2-前往 s3":-2,
    "s3-前往 s4":-2, "s3-前往 s5":0,
    "s4-前往 s5":10, "s4-概率前往":1,
}
gamma = 0.5 # 折扣因子
MDP = (S, A, P, R, gamma)

# 策略 1,随机策略
Pi_1 = {
    "s1-保持 s1":0.5, "s1-前往 s2":0.5,
    "s2-前往 s1":0.5, "s2-前往 s3":0.5,
    "s3-前往 s4":0.5, "s3-前往 s5":0.5,
    "s4-前往 s5":0.5, "s4-概率前往":0.5,
}
# 策略 2
Pi_2 = {
    "s1-保持 s1":0.6, "s1-前往 s2":0.4,
    "s2-前往 s1":0.3, "s2-前往 s3":0.7,
    "s3-前往 s4":0.5, "s3-前往 s5":0.5,
    "s4-前往 s5":0.1, "s4-概率前往":0.9,
}
# 把输入的两个字符串通过“-”连接,便于使用上述定义的 P、R 变量
def join(str1, str2):
    return str1 + '-' + str2


gamma = 0.5
# 转化后的 MRP 的状态转移矩阵
P_from_mdp_to_mrp = [
    [0.5, 0.5, 0.0, 0.0, 0.0],
    [0.5, 0.0, 0.5, 0.0, 0.0],
    [0.0, 0.0, 0.0, 0.5, 0.5],
    [0.0, 0.1, 0.2, 0.2, 0.5],
    [0.0, 0.0, 0.0, 0.0, 1.0],
]
P_from_mdp_to_mrp = np.array(P_from_mdp_to_mrp)
R_from_mdp_to_mrp = [-0.5, -1.5, -1.0, 5.5, 0]

V = compute(P_from_mdp_to_mrp, R_from_mdp_to_mrp, gamma, 5)
print("MDP 中每个状态价值分别为\n", V)